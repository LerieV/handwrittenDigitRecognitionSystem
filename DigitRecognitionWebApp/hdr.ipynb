{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'keras.api.datasets.mnist' from 'C:\\\\Users\\\\Lerie\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\keras\\\\api\\\\datasets\\\\mnist\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lerie\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.4592 - val_accuracy: 0.9653 - val_loss: 0.1135\n",
      "Epoch 2/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9631 - loss: 0.1184 - val_accuracy: 0.9738 - val_loss: 0.0928\n",
      "Epoch 3/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9737 - loss: 0.0840 - val_accuracy: 0.9748 - val_loss: 0.0821\n",
      "Epoch 4/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9775 - loss: 0.0668 - val_accuracy: 0.9800 - val_loss: 0.0737\n",
      "Epoch 5/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0503 - val_accuracy: 0.9767 - val_loss: 0.0839\n",
      "Epoch 6/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0443 - val_accuracy: 0.9802 - val_loss: 0.0759\n",
      "Epoch 7/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0370 - val_accuracy: 0.9830 - val_loss: 0.0696\n",
      "Epoch 8/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0313 - val_accuracy: 0.9813 - val_loss: 0.0784\n",
      "Epoch 9/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0317 - val_accuracy: 0.9812 - val_loss: 0.0755\n",
      "Epoch 10/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0276 - val_accuracy: 0.9810 - val_loss: 0.0804\n",
      "Epoch 11/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0275 - val_accuracy: 0.9818 - val_loss: 0.0763\n",
      "Epoch 12/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0226 - val_accuracy: 0.9818 - val_loss: 0.0807\n",
      "Epoch 13/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0222 - val_accuracy: 0.9805 - val_loss: 0.0844\n",
      "Epoch 14/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0196 - val_accuracy: 0.9785 - val_loss: 0.0952\n",
      "Epoch 15/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0227 - val_accuracy: 0.9792 - val_loss: 0.1015\n",
      "Epoch 16/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9830 - val_loss: 0.0858\n",
      "Epoch 17/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0166 - val_accuracy: 0.9812 - val_loss: 0.0928\n",
      "Epoch 18/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0162 - val_accuracy: 0.9815 - val_loss: 0.0929\n",
      "Epoch 19/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0154 - val_accuracy: 0.9827 - val_loss: 0.0933\n",
      "Epoch 20/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0210 - val_accuracy: 0.9825 - val_loss: 0.0861\n",
      "Epoch 21/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0160 - val_accuracy: 0.9818 - val_loss: 0.1053\n",
      "Epoch 22/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0150 - val_accuracy: 0.9800 - val_loss: 0.1130\n",
      "Epoch 23/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0163 - val_accuracy: 0.9838 - val_loss: 0.0942\n",
      "Epoch 24/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9822 - val_loss: 0.1037\n",
      "Epoch 25/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0138 - val_accuracy: 0.9838 - val_loss: 0.1013\n",
      "Epoch 26/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0144 - val_accuracy: 0.9843 - val_loss: 0.1051\n",
      "Epoch 27/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0129 - val_accuracy: 0.9825 - val_loss: 0.1087\n",
      "Epoch 28/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0151 - val_accuracy: 0.9830 - val_loss: 0.1027\n",
      "Epoch 29/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.9808 - val_loss: 0.1019\n",
      "Epoch 30/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0128 - val_accuracy: 0.9795 - val_loss: 0.1163\n",
      "Epoch 31/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0134 - val_accuracy: 0.9823 - val_loss: 0.1006\n",
      "Epoch 32/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0117 - val_accuracy: 0.9823 - val_loss: 0.1097\n",
      "Epoch 33/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0102 - val_accuracy: 0.9813 - val_loss: 0.1085\n",
      "Epoch 34/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0141 - val_accuracy: 0.9805 - val_loss: 0.1287\n",
      "Epoch 35/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0145 - val_accuracy: 0.9822 - val_loss: 0.1176\n",
      "Epoch 36/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0146 - val_accuracy: 0.9830 - val_loss: 0.1052\n",
      "Epoch 37/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0094 - val_accuracy: 0.9837 - val_loss: 0.1041\n",
      "Epoch 38/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0108 - val_accuracy: 0.9842 - val_loss: 0.1131\n",
      "Epoch 39/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9823 - val_loss: 0.1177\n",
      "Epoch 40/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 0.0133 - val_accuracy: 0.9825 - val_loss: 0.1278\n",
      "Epoch 41/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 0.9827 - val_loss: 0.1225\n",
      "Epoch 42/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0134 - val_accuracy: 0.9818 - val_loss: 0.1299\n",
      "Epoch 43/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0147 - val_accuracy: 0.9828 - val_loss: 0.1259\n",
      "Epoch 44/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9823 - val_loss: 0.1182\n",
      "Epoch 45/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0118 - val_accuracy: 0.9817 - val_loss: 0.1295\n",
      "Epoch 46/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0129 - val_accuracy: 0.9845 - val_loss: 0.1171\n",
      "Epoch 47/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.9853 - val_loss: 0.1115\n",
      "Epoch 48/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 0.9820 - val_loss: 0.1389\n",
      "Epoch 49/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0093 - val_accuracy: 0.9827 - val_loss: 0.1228\n",
      "Epoch 50/50\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0102 - val_accuracy: 0.9835 - val_loss: 0.1153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bed602a510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('handwrittenDigit.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('handwrittenDigit.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.1695\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14361201226711273\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9804999828338623\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.05%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "This digit is probably a 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while os.path.isfile(f\"digits/usoh{image_number}.png\"):\n",
    "    try:\n",
    "        img = cv2.imread(f\"digits/usoh{image_number}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        img = np.invert(np.array([img]))\n",
    "        img = img / 255.0\n",
    "        img = img.reshape(1, 28, 28, 1)\n",
    "        prediction = model.predict(img)\n",
    "        print(f\"This digit is probably a {np.argmax(prediction)}\")\n",
    "        plt.imshow(img[0], cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_number}: {e}\")\n",
    "\n",
    "    finally:\n",
    "        image_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
